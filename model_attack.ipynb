{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "promising-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "import numpy as np\n",
    "import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from bitstring import BitArray\n",
    "import random\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow\n",
    "import torch\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "durable-missile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "[array([[-0.00532808, -0.05634539, -0.01137742, ...,  0.00923991,\n",
      "         0.07452757,  0.00907326],\n",
      "       [ 0.05137911,  0.05812998,  0.04447611, ...,  0.08329046,\n",
      "         0.01642003, -0.00044306],\n",
      "       [ 0.02186788, -0.04802764,  0.01658922, ..., -0.02079115,\n",
      "        -0.00830136, -0.05003768],\n",
      "       ...,\n",
      "       [ 0.01964866, -0.01119061,  0.04589513, ...,  0.01776223,\n",
      "         0.08426769, -0.06542568],\n",
      "       [ 0.07329586, -0.04803493,  0.02275234, ...,  0.08049426,\n",
      "         0.04118011, -0.05224337],\n",
      "       [ 0.03500667,  0.03121211,  0.0386678 , ...,  0.09668488,\n",
      "         0.02840985,  0.03144827]], dtype=float32)\n",
      " array([-0.01711365, -0.01213954, -0.00599254, -0.00734478, -0.05629872,\n",
      "        0.02248463, -0.02807377, -0.00710868, -0.00639182, -0.03171001,\n",
      "       -0.00754629, -0.02898392, -0.00097148, -0.0681415 , -0.03661139,\n",
      "       -0.0153906 ,  0.01178204, -0.04046743, -0.00194255, -0.01513141,\n",
      "       -0.00843685, -0.01373856, -0.04758079, -0.02079848, -0.01953213,\n",
      "       -0.00787513, -0.0060004 , -0.05126738, -0.0185456 , -0.00725576,\n",
      "       -0.00410751, -0.03622087, -0.01367334, -0.0060019 , -0.01160339,\n",
      "       -0.03919316, -0.02693663, -0.03817037, -0.03781998,  0.01100978,\n",
      "       -0.01904443, -0.01094944, -0.00446026, -0.00598002, -0.03282421,\n",
      "       -0.00866615, -0.0069252 , -0.0270882 , -0.01190239, -0.00908277,\n",
      "       -0.00680069, -0.03779548, -0.0565374 , -0.00597805, -0.02145353,\n",
      "       -0.01303975, -0.02607772, -0.0286734 , -0.01364098, -0.04878417,\n",
      "       -0.00659749, -0.00771215, -0.02661368, -0.00464673, -0.01142185,\n",
      "       -0.00532117, -0.00544538, -0.0074341 , -0.02825633, -0.02124301,\n",
      "        0.0030976 , -0.02146929, -0.04834635, -0.01750463, -0.01602463,\n",
      "       -0.03224424, -0.02467368, -0.00584947, -0.02861262, -0.02767017,\n",
      "       -0.00553933, -0.00799963, -0.00636807, -0.02632135, -0.02763748,\n",
      "       -0.0408124 , -0.01340121, -0.00526131,  0.00218792, -0.00846231,\n",
      "       -0.02612121, -0.01355147, -0.00423833, -0.01400837, -0.00400067,\n",
      "       -0.03488685, -0.01086639, -0.00387915,  0.01757234, -0.00712514,\n",
      "       -0.00675135, -0.02783121, -0.02871103, -0.02078816, -0.01443353,\n",
      "       -0.04384573,  0.01150411,  0.00368032, -0.00256341, -0.00449857,\n",
      "       -0.00405256, -0.02407472, -0.00358078, -0.03763657, -0.00960444,\n",
      "       -0.02223419, -0.00467996, -0.00600284,  0.01999113, -0.02980168,\n",
      "       -0.01181527, -0.00599765, -0.01410173, -0.03204022, -0.00554377,\n",
      "       -0.00699118, -0.01299576, -0.01476344, -0.00663137, -0.04135237,\n",
      "       -0.00820324, -0.00547198, -0.0059921 , -0.01327949,  0.00304642,\n",
      "       -0.02123251, -0.01740399, -0.00440049, -0.03149085, -0.04003974,\n",
      "       -0.00837359, -0.01815436, -0.00659406, -0.0225882 , -0.01666562,\n",
      "       -0.05704514, -0.03867883, -0.00792738, -0.00177616, -0.00880749,\n",
      "       -0.05123073, -0.0250279 , -0.02776352, -0.01631048, -0.00595541,\n",
      "        0.00369604, -0.03325037, -0.03378321, -0.02892871, -0.01764318,\n",
      "       -0.0106034 , -0.0502325 , -0.01317768, -0.00719914, -0.04557225,\n",
      "       -0.02681964, -0.00224435, -0.00228291, -0.02223765, -0.00699656,\n",
      "       -0.0557958 , -0.03104055, -0.03459829,  0.01064423, -0.0028591 ,\n",
      "       -0.01555674, -0.03650896, -0.00746977, -0.04372198, -0.00472827,\n",
      "       -0.00795162, -0.02424111, -0.0419873 , -0.03024657, -0.01055002,\n",
      "       -0.0113675 , -0.00591954, -0.0162245 ,  0.01548282, -0.01406449,\n",
      "       -0.02539034,  0.01436711, -0.01039332, -0.008027  , -0.01030768,\n",
      "       -0.03059639, -0.00485594, -0.00779686, -0.01035642, -0.00599763,\n",
      "       -0.01844185, -0.04352902, -0.01851348, -0.03446005, -0.02706043,\n",
      "       -0.0299137 , -0.04853011, -0.03024094, -0.00598661, -0.00596947,\n",
      "       -0.0090697 , -0.04203903, -0.00094627, -0.02424113, -0.04249829,\n",
      "       -0.04507748, -0.02262645, -0.00740846, -0.00752001, -0.00819332,\n",
      "        0.00047805, -0.01383092, -0.00553816, -0.004529  , -0.00817881,\n",
      "       -0.0096592 ,  0.00539859, -0.01630092,  0.00493761, -0.0213605 ,\n",
      "       -0.00600117, -0.04055993, -0.04257732, -0.04422753, -0.00269271,\n",
      "       -0.00032413, -0.0082437 , -0.01012829, -0.02887247, -0.00732514,\n",
      "       -0.00837156,  0.00753935, -0.00403317, -0.02114825, -0.02740992,\n",
      "       -0.03218922,  0.03870544, -0.04140067, -0.00582172, -0.02466019,\n",
      "       -0.04158319, -0.01151318, -0.03792077, -0.02303145, -0.04437259,\n",
      "       -0.00624876], dtype=float32)\n",
      " array([[ 0.02208636, -0.08102674, -0.1714267 , ..., -0.11748584,\n",
      "        -0.06417371, -0.07689817],\n",
      "       [-0.05466014, -0.01059521, -0.03554373, ..., -0.02926782,\n",
      "        -0.02413538, -0.10542096],\n",
      "       [-0.10748451,  0.04850911,  0.05628026, ..., -0.08023575,\n",
      "         0.02566567,  0.020394  ],\n",
      "       ...,\n",
      "       [-0.08349974, -0.03906539, -0.09007359, ...,  0.0776991 ,\n",
      "        -0.07411925,  0.00595328],\n",
      "       [ 0.06925593, -0.08127198,  0.13612263, ..., -0.14721388,\n",
      "         0.15544243,  0.05695758],\n",
      "       [-0.08578715,  0.05602263, -0.15398397, ..., -0.13624799,\n",
      "        -0.3492959 , -0.13055533]], dtype=float32)\n",
      " array([-0.06819682, -0.14801604, -0.08054613, -0.13178413, -0.14947595,\n",
      "        0.04047281, -0.11804633, -0.11475755,  0.19663048, -0.02508909,\n",
      "       -0.01477521, -0.15666002,  0.03986187, -0.05813076, -0.10993998,\n",
      "        0.06045596, -0.07076881, -0.15084098, -0.01330228, -0.09621604,\n",
      "       -0.05378406, -0.05401614,  0.00207063, -0.03210023,  0.09056263,\n",
      "       -0.05639913, -0.10463901, -0.11628868, -0.12638083,  0.00574773,\n",
      "       -0.01063264,  0.07018592, -0.01879476, -0.08018059, -0.08319522,\n",
      "       -0.10379199,  0.07477948, -0.11907918, -0.11197212, -0.03262494,\n",
      "       -0.06513737,  0.23752683,  0.11283892, -0.12255547, -0.16828737,\n",
      "       -0.11939215,  0.09515812, -0.0534508 , -0.07601766, -0.04420587,\n",
      "       -0.00875551, -0.10174103,  0.03141874, -0.08659021, -0.04892303,\n",
      "       -0.06658649, -0.00999613,  0.03885523,  0.01468247, -0.05113569,\n",
      "        0.22751497,  0.01465242,  0.17353246, -0.01461932, -0.11560864,\n",
      "       -0.07114358, -0.0166251 , -0.08421677, -0.03818721,  0.04437792,\n",
      "       -0.13145459,  0.12339544, -0.04583183, -0.06224936, -0.094185  ,\n",
      "       -0.0588011 , -0.06733921,  0.09628062,  0.08927314, -0.03496246,\n",
      "       -0.13836116,  0.19126783, -0.12005379, -0.01096804,  0.11940283,\n",
      "       -0.00674236,  0.07190195, -0.13669999,  0.09264243, -0.14340985,\n",
      "       -0.06072775, -0.11990719, -0.06497679, -0.10333048, -0.05097849,\n",
      "        0.22252345,  0.1505749 , -0.07427005, -0.07947604, -0.15013766,\n",
      "       -0.09908712, -0.16537079, -0.15066887,  0.02960431,  0.09346706,\n",
      "       -0.0972475 , -0.11257473, -0.10126378, -0.11862409,  0.05874227,\n",
      "       -0.09915488, -0.1481833 ,  0.18554844, -0.0377723 , -0.13560532,\n",
      "       -0.02786113,  0.03005465, -0.03850062, -0.16544692, -0.11380814,\n",
      "       -0.08080231,  0.00571084,  0.03275364,  0.10745595, -0.00547811,\n",
      "        0.0519185 ,  0.06343309, -0.07005069, -0.11949591, -0.02379701,\n",
      "       -0.14833665, -0.01932609,  0.13143013, -0.07857234, -0.01022928,\n",
      "       -0.06874462, -0.17657635, -0.11178891, -0.06672591, -0.04760649,\n",
      "       -0.03798669, -0.07523557,  0.0046853 , -0.06966337, -0.01039155,\n",
      "        0.02266365, -0.06505956,  0.01737723, -0.05338722, -0.10382171,\n",
      "       -0.04304336, -0.02005877, -0.07220192,  0.06361014, -0.0803967 ,\n",
      "       -0.04357549, -0.14708148,  0.11565099, -0.06573301, -0.01551364,\n",
      "       -0.0272238 , -0.09268121, -0.13624841, -0.10262417,  0.00841264,\n",
      "       -0.13051511, -0.10327797, -0.11791153, -0.09961737, -0.09740791,\n",
      "       -0.02404423, -0.03765795, -0.02344232, -0.18607283, -0.08055062,\n",
      "       -0.06520012, -0.05929486, -0.03514267, -0.08699817,  0.25072703,\n",
      "       -0.04970542, -0.03777003, -0.02229087,  0.10801066,  0.12557967,\n",
      "       -0.03849287,  0.0140526 , -0.10766612, -0.14842705, -0.06610031,\n",
      "       -0.07511168, -0.0301585 , -0.07796955, -0.06513283, -0.18269834,\n",
      "       -0.05728964, -0.05365686, -0.06132981, -0.01749273, -0.08325092,\n",
      "       -0.15055682,  0.01934407, -0.07209227, -0.08119831, -0.05578617,\n",
      "       -0.1723471 , -0.08963927, -0.04848118, -0.14673942, -0.13258861,\n",
      "       -0.09090948, -0.11561696,  0.0445108 ,  0.0321512 ,  0.00164599,\n",
      "       -0.05717448, -0.10445863, -0.11807123, -0.0885716 , -0.19448084,\n",
      "       -0.05647899, -0.0699356 , -0.16630898, -0.03015703, -0.20029101,\n",
      "       -0.01450027,  0.07485387, -0.02156981, -0.06219728,  0.03642766,\n",
      "       -0.09317486, -0.04824663,  0.03184918, -0.09654818, -0.05318678,\n",
      "       -0.1124327 ,  0.07637198,  0.19061422, -0.11881378, -0.14461428,\n",
      "       -0.04308382, -0.06961532, -0.16539152, -0.05922171,  0.03619584,\n",
      "       -0.04130285, -0.11769641, -0.01731377,  0.14554812, -0.08247795,\n",
      "       -0.01908971, -0.10870061, -0.05458307, -0.03919761,  0.01508951,\n",
      "       -0.12727076], dtype=float32)\n",
      " array([[-0.09689313,  0.1422785 , -0.03487078, ..., -0.22630101,\n",
      "        -0.02487821, -0.07318975],\n",
      "       [ 0.10267327, -0.23354048, -0.07437838, ..., -0.01796446,\n",
      "        -0.02210947, -0.03927209],\n",
      "       [-0.05254815, -0.13076329,  0.17942467, ..., -0.11636718,\n",
      "        -0.23292911, -0.07568337],\n",
      "       ...,\n",
      "       [ 0.01843082, -0.02417218,  0.14436488, ...,  0.06700257,\n",
      "        -0.13854887, -0.13350329],\n",
      "       [-0.00237031, -0.17757857,  0.23586692, ...,  0.00528557,\n",
      "        -0.01354495, -0.07201949],\n",
      "       [ 0.01442982,  0.07092398, -0.03830795, ...,  0.15649082,\n",
      "        -0.06516016, -0.081547  ]], dtype=float32)\n",
      " array([-0.06244262, -0.1540803 , -0.01175604, -0.08665229, -0.04212891,\n",
      "        0.01250402, -0.08954314, -0.1684384 , -0.10764939,  0.01678694,\n",
      "       -0.11495388, -0.0660053 , -0.26707822, -0.04575631,  0.05083898,\n",
      "        0.21418795, -0.12764451, -0.02433331, -0.06319074, -0.1279438 ,\n",
      "       -0.06707134, -0.05384291,  0.07105347, -0.05064037, -0.14445822,\n",
      "       -0.16065766, -0.04228631, -0.08968291, -0.17978905,  0.2792756 ,\n",
      "       -0.11426384,  0.02156728, -0.11660901,  0.10335156, -0.13631848,\n",
      "       -0.12754014, -0.16500112,  0.34469062, -0.08594193, -0.11520683,\n",
      "       -0.13536729,  0.09028657, -0.171138  , -0.0915748 ,  0.10494395,\n",
      "       -0.04861557, -0.09621231, -0.11986878, -0.03010296, -0.09463164,\n",
      "        0.0846856 ,  0.11691432,  0.0175958 ,  0.01242105, -0.13413066,\n",
      "       -0.13420251, -0.00966292,  0.25794333, -0.08078991,  0.16994585,\n",
      "       -0.07186999, -0.1502684 , -0.06048183, -0.04971641, -0.05138028,\n",
      "       -0.00852082,  0.22511336,  0.03215538, -0.07158125, -0.11923544,\n",
      "        0.28917086, -0.0621341 , -0.12076208, -0.15156595, -0.03352235,\n",
      "        0.14716633,  0.00535649,  0.04554924, -0.03251706, -0.04452129,\n",
      "       -0.01487955, -0.11308505, -0.14694384, -0.11670305,  0.08569759,\n",
      "       -0.22061525,  0.0983571 ,  0.00684711, -0.10922704, -0.08608016,\n",
      "       -0.15644513, -0.10158331, -0.19657512, -0.11245157,  0.17258139,\n",
      "        0.3067962 , -0.01483956, -0.20928289, -0.08984414, -0.00654736,\n",
      "       -0.06610941, -0.15434898, -0.06561831,  0.28424653, -0.1487908 ,\n",
      "        0.00644431, -0.1509162 , -0.07192384, -0.07957993,  0.26105323,\n",
      "        0.13388963, -0.30146363, -0.2260993 , -0.14297634, -0.11646796,\n",
      "       -0.04588935, -0.0314011 ,  0.27290928, -0.03662132, -0.16506371,\n",
      "       -0.06569464, -0.15312101, -0.17614147, -0.08863258,  0.27930224,\n",
      "        0.03930212,  0.015042  , -0.03901243,  0.24417974, -0.18250845,\n",
      "       -0.0011617 , -0.11886501,  0.15095632,  0.170179  ,  0.01515902,\n",
      "       -0.14006738, -0.06655974, -0.12527514, -0.03267973, -0.22025725,\n",
      "       -0.05402298, -0.13754638, -0.19945927,  0.1248861 , -0.2534457 ,\n",
      "       -0.17911619, -0.06022461,  0.2661097 , -0.16524343, -0.09835291,\n",
      "        0.02952402, -0.20330493,  0.04501832, -0.09465251,  0.08810619,\n",
      "       -0.13266876, -0.15784892, -0.17198029, -0.14593671, -0.1995749 ,\n",
      "       -0.13416436, -0.03045998,  0.01128554, -0.05391432, -0.089621  ,\n",
      "       -0.02852601, -0.1271623 ,  0.1770134 ,  0.03019221,  0.08734202,\n",
      "       -0.12880519, -0.08163968,  0.18407498, -0.18286622,  0.03975158,\n",
      "       -0.01394722, -0.07510011, -0.00431243,  0.06370867,  0.26256073,\n",
      "        0.02596645, -0.14022525, -0.11079799, -0.16061166, -0.0805127 ,\n",
      "       -0.15424836, -0.06077323, -0.04972912, -0.1760162 , -0.09425194,\n",
      "       -0.19187315, -0.08845568, -0.07982204, -0.01961216, -0.13035229,\n",
      "        0.10689744, -0.01327068,  0.14309384, -0.10259455, -0.04232288,\n",
      "       -0.14464283, -0.01891217, -0.06194203, -0.0592259 , -0.03157097,\n",
      "       -0.20640813, -0.1066783 ,  0.20901425, -0.19471784, -0.09611865,\n",
      "       -0.01244699, -0.18840627, -0.19888538, -0.09188179, -0.02340635,\n",
      "       -0.06095832, -0.2269238 ,  0.08513269,  0.08980545,  0.17661904,\n",
      "        0.0289686 ,  0.31610975,  0.20859997,  0.20378973, -0.1929491 ,\n",
      "       -0.07788676, -0.19009872,  0.13530575,  0.05992831, -0.1589872 ,\n",
      "        0.0022325 , -0.0877147 , -0.01451572, -0.13035744, -0.18635617,\n",
      "       -0.24587311, -0.06917803, -0.15163685, -0.02030701, -0.20948152,\n",
      "       -0.04128865,  0.12267316, -0.10172687,  0.02972011,  0.0977076 ,\n",
      "       -0.1458988 , -0.0503165 , -0.17743087, -0.07285295, -0.07817191,\n",
      "        0.19693673, -0.03857832, -0.03998775, -0.04149512,  0.15051839,\n",
      "       -0.16497974], dtype=float32)\n",
      " array([[-0.09769457, -0.09323361, -0.11864392, ..., -0.01983366,\n",
      "         0.17928447, -0.01633757],\n",
      "       [ 0.06272832, -0.14443673,  0.06441694, ..., -0.10672352,\n",
      "        -0.124622  ,  0.03745692],\n",
      "       [ 0.10635233, -0.05846164, -0.03187671, ..., -0.31451368,\n",
      "        -0.00840604, -0.06130619],\n",
      "       ...,\n",
      "       [ 0.03537327, -0.2715312 ,  0.0876127 , ..., -0.10185494,\n",
      "        -0.13153526,  0.11034345],\n",
      "       [ 0.01687947, -0.4051193 ,  0.15148214, ...,  0.00542233,\n",
      "         0.09195596,  0.01465765],\n",
      "       [-0.09988726,  0.06465258, -0.09444872, ..., -0.08282603,\n",
      "        -0.02064028, -0.11356895]], dtype=float32)\n",
      " array([-0.01356889, -0.1031001 , -0.15770887,  0.01499791, -0.02286211,\n",
      "       -0.17058462, -0.0372915 , -0.16653174,  0.44839674,  0.09653454],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-f5828c680f02>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  w = np.array(model.get_weights())\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "w = np.array(model.get_weights())\n",
    "print(w)\n",
    "\n",
    "model.set_weights(w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radical-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w2 = abs(w)\n",
    "m1 = 0\n",
    "maxw = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "yellow-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(w2)):\n",
    "    m1 = np.amax(w2[i])\n",
    "    maxw.append(m1)\n",
    "mw = np.amax(maxw)\n",
    "w = w/mw\n",
    "w = w * 127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "actual-funeral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,6):\n",
    "    w[i] = w[i].astype('int')\n",
    "\n",
    "print (type(w[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elegant-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [w[0], w[2], w[4], w[6]]\n",
    "\n",
    "# network architecture\n",
    "#256-256-256-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-mitchell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "considerable-producer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6 10 -1 ...  1 -8  1]\n",
      " [ 2  7  5 ... 10  2  2]\n",
      " [14 -6 14 ... -2 14 -6]\n",
      " ...\n",
      " [ 2 -1  7 ...  2  7 -8]\n",
      " [ 9 -6  2 ... 10  5 -6]\n",
      " [ 4  3  4 ... 12  3  3]]\n",
      "[[  2 -10 -21 ... -14  -8  -9]\n",
      " [ -6  -2  -4 ... -28 -28 -13]\n",
      " [-13   6   7 ... -10   3 -11]\n",
      " ...\n",
      " [-10   5 -11 ... -12  -9   1]\n",
      " [  8 -10  12 ... -18  19   7]\n",
      " [-10   7 -19 ... -22 -43 -16]]\n",
      "[[ 16  17  -4 ... -28  -3  -9]\n",
      " [ 12 -29  -9 ...  -2  -2  -4]\n",
      " [ -6 -16  22 ... -14 -29  -9]\n",
      " ...\n",
      " [  2  -3  18 ...   8 -17 -16]\n",
      " [  0 -22  29 ...   0  -1  -9]\n",
      " [  1   8  -4 ...  19  -8 -10]]\n",
      "[[ -4.887619   -4.887619   -4.887619  ...  -2.4868052  22.479237\n",
      "   -2.0484543]\n",
      " [  7.8650694 -18.10992     8.076795  ... -15.625489  -15.625489\n",
      "  -15.625489 ]\n",
      " [ 13.334781   -3.9967995  -3.9967995 ...  -1.053975   -1.053975\n",
      "   -1.053975 ]\n",
      " ...\n",
      " [ -8.410854   -8.410854   -8.410854  ... -12.770885  -16.492294\n",
      "  -16.492294 ]\n",
      " [-50.7951    -50.7951     18.993296  ...   1.8378216   1.8378216\n",
      "    1.8378216]\n",
      " [  8.1063385   8.1063385 -11.84227   ... -10.384981   -2.5879421\n",
      "  -14.239623 ]]\n"
     ]
    }
   ],
   "source": [
    "missing_values = []\n",
    "for layer in weights:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "waiting-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplication function\n",
    "def dupWeights(num_weight, weights):\n",
    "    for layer in weights:\n",
    "        n = num_weight\n",
    "        while(n > 0):\n",
    "            \n",
    "            # random weight index\n",
    "            vec = layer[random.randrange(0, layer.size)]\n",
    "            index = random.randrange(0, vec.size)\n",
    "            missing_values.append(vec[index])\n",
    "            # neighbor of random weight index\n",
    "            neighbor = index\n",
    "            if(index != vec.size - 1):\n",
    "                neighbor += 1\n",
    "            else: \n",
    "                neighbor -= 1\n",
    "\n",
    "            # duplicate random indeces\n",
    "            duplicate(vec[index], vec[neighbor], vec)\n",
    "\n",
    "        # decrement num counter\n",
    "            n = n - 1\n",
    "\n",
    "    return weights\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "alert-relationship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "several-dayton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "annual-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate only one of the weights in each layer\n",
    "dup_arr = dupWeights(2, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "opening-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "w[0] = dup_arr[0] \n",
    "w[2] = dup_arr[1] \n",
    "w[4] = dup_arr[2] \n",
    "w[6] = dup_arr[3] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "returning-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model weights to duplicated weights\n",
    "model.set_weights(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepted-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist training and testing data\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "modular-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "train_images = (train_images/255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "german-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "train_images = train_images.reshape((-1, 784))\n",
    "test_images = test_images.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "surprised-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "changing-twelve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 69316264.0000 - accuracy: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[69316264.0, 0.879800021648407]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(\n",
    "    test_images,\n",
    "    to_categorical(test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "constitutional-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten layer\n",
    "wf0 = w[0].flatten()\n",
    "wf1 = w[2].flatten()\n",
    "wf2 = w[4].flatten()\n",
    "wf3 = w[6].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "burning-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate(num1, num2, arr):\n",
    "    count = 0\n",
    "    for val in arr:\n",
    "        if(val == num2):\n",
    "            arr[count] = num1\n",
    "        count += 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "recorded-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(x, arr):\n",
    "    for val in arr:\n",
    "        if(val == x):\n",
    "            print(\"Found\")\n",
    "    print(\"Not Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "confident-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplication(number_of_duplications, flat_layer, layer_index):\n",
    "    \n",
    "    \"\"\"\n",
    "    flat_layer: flatten hidden weights from the model\n",
    "    layer_index: index to hidden weights\n",
    "    number_of_duplications: number of weights being duplicated\n",
    "    \"\"\"\n",
    "    \n",
    "    n = number_of_duplications\n",
    "    # get random values for each layer\n",
    "    while(n > 0):\n",
    "        r00 = random.randrange(0, len(flat_layer) - 1)\n",
    "        r01 = r00 + 1\n",
    "        # Duplicate random value\n",
    "        flat_layer = duplicate(flat_layer[r00], flat_layer[r01], flat_layer)\n",
    "        n -= 1\n",
    "\n",
    "    \n",
    "\n",
    "    # reshape layer\n",
    "    wf00 = flat_layer.reshape(w[layer_index].shape)\n",
    "    w[layer_index] = wf00 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "immune-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy():\n",
    "    # change model weights to duplicated weights\n",
    "    model.set_weights(w)\n",
    "\n",
    "    # predict on the 1000 test images\n",
    "    predictions = model.predict(test_images[:10000])\n",
    "\n",
    "    # print our model's predictions\n",
    "    #print(np.argmax(predictions, axis=1)) \n",
    "\n",
    "\n",
    "    # check our predictions against the ground truths\n",
    "    #print(test_labels[:1000])\n",
    "\n",
    "    x = np.argmax(predictions, axis=1)\n",
    "    y = test_labels[:10000]\n",
    "\n",
    "    count = 0\n",
    "    for i in range (0, 10000):\n",
    "        if x[i] == y[i]:\n",
    "            count = count + 1\n",
    "    # get accuracy of model with for loop\n",
    "    #print(\"accuracy =\", count / 10000)\n",
    "    return (count / 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "narrow-mercy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  0  accuracy  0.904\n",
      "n =  0  accuracy  0.887\n",
      "n =  0  accuracy  0.887\n",
      "n =  0  accuracy  0.8869\n",
      "n =  0  accuracy  0.887\n",
      "n =  0  accuracy  0.8861\n",
      "n =  0  accuracy  0.8859\n",
      "n =  0  accuracy  0.886\n",
      "n =  0  accuracy  0.8859\n",
      "n =  0  accuracy  0.8854\n",
      "n =  1  accuracy  0.8854\n",
      "n =  1  accuracy  0.8854\n",
      "n =  1  accuracy  0.8848\n",
      "n =  1  accuracy  0.8849\n",
      "n =  1  accuracy  0.8849\n",
      "n =  1  accuracy  0.885\n",
      "n =  1  accuracy  0.8849\n",
      "n =  1  accuracy  0.8851\n",
      "n =  1  accuracy  0.8851\n",
      "n =  1  accuracy  0.8851\n",
      "n =  2  accuracy  0.8868\n",
      "n =  2  accuracy  0.8867\n",
      "n =  2  accuracy  0.8867\n",
      "n =  2  accuracy  0.8868\n",
      "n =  2  accuracy  0.8867\n",
      "n =  2  accuracy  0.8867\n",
      "n =  2  accuracy  0.8867\n",
      "n =  2  accuracy  0.8867\n",
      "n =  2  accuracy  0.8866\n",
      "n =  2  accuracy  0.8865\n",
      "n =  3  accuracy  0.8868\n",
      "n =  3  accuracy  0.8868\n",
      "n =  3  accuracy  0.8871\n",
      "n =  3  accuracy  0.887\n",
      "n =  3  accuracy  0.887\n",
      "n =  3  accuracy  0.8831\n",
      "n =  3  accuracy  0.8831\n",
      "n =  3  accuracy  0.8827\n",
      "n =  3  accuracy  0.884\n",
      "n =  3  accuracy  0.8839\n",
      "n =  4  accuracy  0.884\n",
      "n =  4  accuracy  0.884\n",
      "n =  4  accuracy  0.884\n",
      "n =  4  accuracy  0.8842\n",
      "n =  4  accuracy  0.8832\n",
      "n =  4  accuracy  0.8832\n",
      "n =  4  accuracy  0.8833\n",
      "n =  4  accuracy  0.8835\n",
      "n =  4  accuracy  0.8782\n",
      "n =  4  accuracy  0.878\n",
      "n =  5  accuracy  0.878\n",
      "n =  5  accuracy  0.878\n",
      "n =  5  accuracy  0.8775\n",
      "n =  5  accuracy  0.8772\n",
      "n =  5  accuracy  0.8772\n",
      "n =  5  accuracy  0.8767\n",
      "n =  5  accuracy  0.8768\n",
      "n =  5  accuracy  0.8766\n",
      "n =  5  accuracy  0.8744\n",
      "n =  5  accuracy  0.8742\n",
      "n =  6  accuracy  0.8742\n",
      "n =  6  accuracy  0.8742\n",
      "n =  6  accuracy  0.8742\n",
      "n =  6  accuracy  0.874\n",
      "n =  6  accuracy  0.874\n",
      "n =  6  accuracy  0.8747\n",
      "n =  6  accuracy  0.8746\n",
      "n =  6  accuracy  0.8747\n",
      "n =  6  accuracy  0.8747\n",
      "n =  6  accuracy  0.8747\n",
      "n =  7  accuracy  0.8746\n",
      "n =  7  accuracy  0.8758\n",
      "n =  7  accuracy  0.8759\n",
      "n =  7  accuracy  0.8762\n",
      "n =  7  accuracy  0.8738\n",
      "n =  7  accuracy  0.8738\n",
      "n =  7  accuracy  0.8992\n",
      "n =  7  accuracy  0.8987\n",
      "n =  7  accuracy  0.8986\n",
      "n =  7  accuracy  0.8986\n",
      "n =  8  accuracy  0.899\n",
      "n =  8  accuracy  0.8985\n",
      "n =  8  accuracy  0.8985\n",
      "n =  8  accuracy  0.8984\n",
      "n =  8  accuracy  0.8983\n",
      "n =  8  accuracy  0.8984\n",
      "n =  8  accuracy  0.8982\n",
      "n =  8  accuracy  0.8982\n",
      "n =  8  accuracy  0.8983\n",
      "n =  8  accuracy  0.8983\n",
      "n =  9  accuracy  0.8983\n",
      "n =  9  accuracy  0.8971\n",
      "n =  9  accuracy  0.8972\n",
      "n =  9  accuracy  0.8972\n",
      "n =  9  accuracy  0.8968\n",
      "n =  9  accuracy  0.8968\n",
      "n =  9  accuracy  0.8964\n",
      "n =  9  accuracy  0.8963\n",
      "n =  9  accuracy  0.8967\n",
      "n =  9  accuracy  0.8967\n",
      "n =  10  accuracy  0.8967\n",
      "n =  10  accuracy  0.8967\n",
      "n =  10  accuracy  0.8967\n",
      "n =  10  accuracy  0.8969\n",
      "n =  10  accuracy  0.8971\n",
      "n =  10  accuracy  0.8971\n",
      "n =  10  accuracy  0.8972\n",
      "n =  10  accuracy  0.8972\n",
      "n =  10  accuracy  0.8972\n",
      "n =  10  accuracy  0.8972\n",
      "n =  11  accuracy  0.8968\n",
      "n =  11  accuracy  0.8968\n",
      "n =  11  accuracy  0.8966\n",
      "n =  11  accuracy  0.8966\n",
      "n =  11  accuracy  0.8966\n",
      "n =  11  accuracy  0.8966\n",
      "n =  11  accuracy  0.8968\n",
      "n =  11  accuracy  0.8967\n",
      "n =  11  accuracy  0.8967\n",
      "n =  11  accuracy  0.8967\n",
      "n =  12  accuracy  0.8967\n",
      "n =  12  accuracy  0.8966\n",
      "n =  12  accuracy  0.8957\n",
      "n =  12  accuracy  0.8958\n",
      "n =  12  accuracy  0.8959\n",
      "n =  12  accuracy  0.8959\n",
      "n =  12  accuracy  0.8962\n",
      "n =  12  accuracy  0.8953\n",
      "n =  12  accuracy  0.8953\n",
      "n =  12  accuracy  0.8955\n",
      "n =  13  accuracy  0.8955\n",
      "n =  13  accuracy  0.8955\n",
      "n =  13  accuracy  0.8955\n",
      "n =  13  accuracy  0.8953\n",
      "n =  13  accuracy  0.8952\n",
      "n =  13  accuracy  0.8954\n",
      "n =  13  accuracy  0.8953\n",
      "n =  13  accuracy  0.896\n",
      "n =  13  accuracy  0.8951\n",
      "n =  13  accuracy  0.895\n",
      "n =  14  accuracy  0.895\n",
      "n =  14  accuracy  0.895\n",
      "n =  14  accuracy  0.8653\n",
      "n =  14  accuracy  0.8653\n",
      "n =  14  accuracy  0.8653\n",
      "n =  14  accuracy  0.8653\n",
      "n =  14  accuracy  0.8657\n",
      "n =  14  accuracy  0.8639\n",
      "n =  14  accuracy  0.8639\n",
      "n =  14  accuracy  0.8615\n",
      "n =  15  accuracy  0.8615\n",
      "n =  15  accuracy  0.8606\n",
      "n =  15  accuracy  0.8576\n",
      "n =  15  accuracy  0.8587\n",
      "n =  15  accuracy  0.858\n",
      "n =  15  accuracy  0.858\n",
      "n =  15  accuracy  0.858\n",
      "n =  15  accuracy  0.8558\n",
      "n =  15  accuracy  0.8558\n",
      "n =  15  accuracy  0.8519\n",
      "n =  16  accuracy  0.8553\n",
      "n =  16  accuracy  0.8553\n",
      "n =  16  accuracy  0.8533\n",
      "n =  16  accuracy  0.8533\n",
      "n =  16  accuracy  0.8532\n",
      "n =  16  accuracy  0.8463\n",
      "n =  16  accuracy  0.8463\n",
      "n =  16  accuracy  0.8463\n",
      "n =  16  accuracy  0.8463\n",
      "n =  16  accuracy  0.8462\n",
      "n =  17  accuracy  0.8469\n",
      "n =  17  accuracy  0.8469\n",
      "n =  17  accuracy  0.8468\n",
      "n =  17  accuracy  0.8537\n",
      "n =  17  accuracy  0.8536\n",
      "n =  17  accuracy  0.8536\n",
      "n =  17  accuracy  0.8538\n",
      "n =  17  accuracy  0.8538\n",
      "n =  17  accuracy  0.8538\n",
      "n =  17  accuracy  0.8538\n",
      "n =  18  accuracy  0.8544\n",
      "n =  18  accuracy  0.8544\n",
      "n =  18  accuracy  0.8577\n",
      "n =  18  accuracy  0.8649\n",
      "n =  18  accuracy  0.8652\n",
      "n =  18  accuracy  0.8575\n",
      "n =  18  accuracy  0.8571\n",
      "n =  18  accuracy  0.857\n",
      "n =  18  accuracy  0.8569\n",
      "n =  18  accuracy  0.857\n",
      "n =  19  accuracy  0.8563\n",
      "n =  19  accuracy  0.8562\n",
      "n =  19  accuracy  0.8562\n",
      "n =  19  accuracy  0.8556\n",
      "n =  19  accuracy  0.8557\n",
      "n =  19  accuracy  0.8561\n",
      "n =  19  accuracy  0.8558\n",
      "n =  19  accuracy  0.8563\n",
      "n =  19  accuracy  0.8574\n",
      "n =  19  accuracy  0.8575\n",
      "n =  20  accuracy  0.857\n",
      "n =  20  accuracy  0.8572\n",
      "n =  20  accuracy  0.857\n",
      "n =  20  accuracy  0.8557\n",
      "n =  20  accuracy  0.8503\n",
      "n =  20  accuracy  0.8503\n",
      "n =  20  accuracy  0.8504\n",
      "n =  20  accuracy  0.8503\n",
      "n =  20  accuracy  0.8495\n",
      "n =  20  accuracy  0.85\n",
      "n =  21  accuracy  0.8499\n",
      "n =  21  accuracy  0.8493\n",
      "n =  21  accuracy  0.8493\n",
      "n =  21  accuracy  0.8473\n",
      "n =  21  accuracy  0.8473\n",
      "n =  21  accuracy  0.8474\n",
      "n =  21  accuracy  0.8474\n",
      "n =  21  accuracy  0.8504\n",
      "n =  21  accuracy  0.8504\n",
      "n =  21  accuracy  0.8482\n",
      "n =  22  accuracy  0.8479\n",
      "n =  22  accuracy  0.8479\n",
      "n =  22  accuracy  0.8471\n",
      "n =  22  accuracy  0.8468\n",
      "n =  22  accuracy  0.8468\n",
      "n =  22  accuracy  0.8468\n",
      "n =  22  accuracy  0.8476\n",
      "n =  22  accuracy  0.8482\n",
      "n =  22  accuracy  0.8482\n",
      "n =  22  accuracy  0.8482\n",
      "n =  23  accuracy  0.8486\n",
      "n =  23  accuracy  0.8486\n",
      "n =  23  accuracy  0.8482\n",
      "n =  23  accuracy  0.8481\n",
      "n =  23  accuracy  0.8496\n",
      "n =  23  accuracy  0.8346\n",
      "n =  23  accuracy  0.8348\n",
      "n =  23  accuracy  0.8343\n",
      "n =  23  accuracy  0.8235\n",
      "n =  23  accuracy  0.8235\n",
      "n =  24  accuracy  0.8235\n",
      "n =  24  accuracy  0.8234\n",
      "n =  24  accuracy  0.8271\n",
      "n =  24  accuracy  0.8271\n",
      "n =  24  accuracy  0.8271\n",
      "n =  24  accuracy  0.8271\n",
      "n =  24  accuracy  0.8285\n",
      "n =  24  accuracy  0.8288\n",
      "n =  24  accuracy  0.8454\n",
      "n =  24  accuracy  0.8437\n",
      "n =  25  accuracy  0.8439\n",
      "n =  25  accuracy  0.8439\n",
      "n =  25  accuracy  0.8569\n",
      "n =  25  accuracy  0.8575\n",
      "n =  25  accuracy  0.8575\n",
      "n =  25  accuracy  0.8574\n",
      "n =  25  accuracy  0.8576\n",
      "n =  25  accuracy  0.857\n",
      "n =  25  accuracy  0.857\n",
      "n =  25  accuracy  0.8568\n",
      "n =  26  accuracy  0.8568\n",
      "n =  26  accuracy  0.8513\n",
      "n =  26  accuracy  0.85\n",
      "n =  26  accuracy  0.85\n",
      "n =  26  accuracy  0.85\n",
      "n =  26  accuracy  0.85\n",
      "n =  26  accuracy  0.8498\n",
      "n =  26  accuracy  0.8497\n",
      "n =  26  accuracy  0.8496\n",
      "n =  26  accuracy  0.8498\n",
      "n =  27  accuracy  0.8498\n",
      "n =  27  accuracy  0.8471\n",
      "n =  27  accuracy  0.8471\n",
      "n =  27  accuracy  0.8469\n",
      "n =  27  accuracy  0.847\n",
      "n =  27  accuracy  0.8471\n",
      "n =  27  accuracy  0.8471\n",
      "n =  27  accuracy  0.8461\n",
      "n =  27  accuracy  0.8451\n",
      "n =  27  accuracy  0.8451\n",
      "n =  28  accuracy  0.8451\n",
      "n =  28  accuracy  0.8453\n",
      "n =  28  accuracy  0.8455\n",
      "n =  28  accuracy  0.8454\n",
      "n =  28  accuracy  0.8454\n",
      "n =  28  accuracy  0.8423\n",
      "n =  28  accuracy  0.8423\n",
      "n =  28  accuracy  0.8422\n",
      "n =  28  accuracy  0.8422\n",
      "n =  28  accuracy  0.8422\n",
      "n =  29  accuracy  0.8406\n",
      "n =  29  accuracy  0.8406\n",
      "n =  29  accuracy  0.8402\n",
      "n =  29  accuracy  0.8428\n",
      "n =  29  accuracy  0.8427\n",
      "n =  29  accuracy  0.8428\n",
      "n =  29  accuracy  0.8428\n",
      "n =  29  accuracy  0.8257\n",
      "n =  29  accuracy  0.826\n",
      "n =  29  accuracy  0.826\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "accuracies.append(get_accuracy())\n",
    "n = 0\n",
    "while(n < 30):\n",
    "    # duplicate each layer of the model\n",
    "    count = 0\n",
    "    sum_accuracies = 0\n",
    "    while(count < 10):\n",
    "        duplication(1, wf0, 0)\n",
    "        duplication(1, wf1, 2)\n",
    "        duplication(1, wf2, 4)\n",
    "        duplication(1, wf3, 6)\n",
    "        accuracy = get_accuracy()\n",
    "        print(\"n = \", n, \" accuracy \", accuracy)\n",
    "        sum_accuracies += accuracy\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    \n",
    "    # get accuracy of model after each duplication\n",
    "    accuracies.append(sum_accuracies / 10)\n",
    "    # increment n\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "small-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9042, 0.8881200000000001, 0.8850599999999998, 0.8866900000000001, 0.88515, 0.88256, 0.8766599999999999, 0.8744, 0.88452, 0.8984100000000002, 0.89695, 0.8969999999999999, 0.8966899999999999, 0.89589, 0.8953799999999997, 0.87062, 0.8575900000000001, 0.8501800000000002, 0.8516699999999998, 0.8582099999999999, 0.85631, 0.8527699999999999, 0.8486900000000002, 0.84755, 0.8393799999999999, 0.8301699999999999, 0.85455, 0.8507, 0.84684, 0.8437899999999999, 0.8370200000000001]\n"
     ]
    }
   ],
   "source": [
    "print(accuracies)\n",
    "x = []\n",
    "for val in range(30):\n",
    "    x.append(val + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "convertible-building",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "worth-document",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (31), usually from a call to set_ticks, does not match the number of ticklabels (30).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-38fbb33996c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compare'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mxticks\u001b[0;34m(ticks, labels, **kwargs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1717\u001b[0m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (31), usually from a call to set_ticks, does not match the number of ticklabels (30)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create an index for each tick position\n",
    "# x was created above\n",
    "xi = list(range(len(x) + 1))\n",
    "y = accuracies\n",
    "plt.ylim(0.75,.95)\n",
    "# plot the index for the x-values\n",
    "plt.plot(xi, y, marker='o', linestyle='--', color='r', label='Square') \n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y') \n",
    "plt.xticks(xi, x)\n",
    "plt.title('compare')\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-study",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
